---
title: "Sally the Congressperson: A Psycho- and Sociolinguistic Investigation into the Relationship Between Ideology, Gender, and Language: Final Processing Model"
output: html_notebook
---

# Preliminaries 

## Setting up the Notebook

For this write-up and analysis, I require the following packages, loaded in here:

```{r echo=TRUE}
library(ggplot2) 
library(tidyverse) 
library(lme4) 
library(lmerTest)
library(brms)

source("helpers.R")
```

I also use a custom color palette, so I include the code for that here as well^[It is my hope and intention that this color palette is color-blind friendly. If you have accessibility concerns, please do not hesitate to reach out to me!]. I also set the default ggplot theme to theme_minimal for personal aesthetic reasons.

```{r}
bran_palette = c("#7ae7e5", "#fe5f55", "#B2A6DE", "#14342b", "#69385c")

theme_set(theme_minimal())
```

```{r}
`%notin%` <- Negate(`%in%`)
```

```{r}
ad_lexemes <- c("actor","host","hunter","villain","heir","hero")
```

## Frequency Data

In order to account for potential effects of the relative frequency of these items, we also want to include frequency values for each form and lexeme. Frequencies were collected from the "Spoken" part of the [Corpus of Contemporary American English](https://www.english-corpora.org/coca/). The "Spoken" part of COCA consists of transcripts from ABC, CNN, PBS, NBC, MSNBC, NPR, CBS, and FOX, as well as a small collcetion of independent news sources. We read in the frequency values of the twenty critical items here:

```{r}
frequency <- read.csv("freq_vals.csv")
```

One of the working questions in this investigation is: what is the role of media influence in the processing and production of these gender-neutral social role titles? In order to investigate this question, we likely shouldn't ascribe the same frequency values to all participants, especially when the corpus from which the frequency values are derived includes the media source the tokens come from. As such, we can coalesce the left-wing media sources into a single "left-wing frequency" value, and do the same to the right-wing media (which, in COCA, is just FOX). The relative left-vs-right media biases are taken from the [Ad Fontes Media Bias Chart](https://adfontesmedia.com). 

```{r}
lib_cols <- c('ABC','CNN','PBS','NBC','MSNBC','NPR','CBS')
```

```{r}
frequency <- frequency %>%
  mutate(total_left = rowSums(frequency[lib_cols])) %>%
  mutate(total_right = FOX) %>%
  mutate(all_wpm = ((total_left + total_right) / 121500000) * 1000000) %>%
  mutate(left_wpm = (total_left/109300000) * 1000000) %>%
  mutate(right_wpm = (total_right/12200000) * 1000000) %>%
  mutate(neutral_binary = case_when(
    gender == 'neutral' ~ as.numeric(1),
    TRUE ~ as.numeric(0)
  )) %>%
  mutate(morph_type = case_when(
    lexeme %notin% ad_lexemes ~ "compound",
    TRUE ~ "adoption"
  ))
```


frequency <- frequency %>%
  group_by(word) %>%
  summarise(mean_freq_left = mean(left_wpm), mean_freq_right = mean(right_wpm), mean_freq_all = mean(all_wpm)) %>%
  rename(form = word)

Re-write frequency to avoid zero numbers!

```{r}
frequency[frequency == 0.00000000] <- 0.0001
```

Take log frequency of each media type.

```{r}
frequency <- frequency %>% 
  mutate(div = all_wpm/1000000) %>% 
  mutate(nex = div*100) %>% 
  mutate(prob = nex/100) %>% 
  mutate(log_all = -log(prob)) %>%
  mutate(div = left_wpm/1000000) %>% 
  mutate(nex = div*100) %>% 
  mutate(prob = nex/100) %>% 
  mutate(log_left = -log(prob)) %>% 
  mutate(div =right_wpm/1000000) %>% 
  mutate(nex = div*100) %>% 
  mutate(prob = nex/100) %>% 
  mutate(log_right = -log(prob)) %>% 
  rename(form = word) %>% 
  select(form,gender,log_all,log_left,log_right)
```



frequency <- frequency %>%
  mutate(log_right = log(mean_freq_right), log_left = log(mean_freq_left)) 


### Analysis

**Reading in the Data**

```{r}
maze_data <- read.csv('maze_data.csv') %>%
  filter(trial_id!= 'example') %>%
  filter(region=='critical')
```

**Exclusions** 

Now, we want to exclude any participants who failed to answer at least 85% of the attention check questions correctly. We do this by creating a list of all participants who scored less than 85% on these checks, and then cross-referencing this list with all data points, removing any data points whose participants were in the exclusion list. 

```{r}
maze_exclusion <- maze_data %>% group_by(workerid) %>%
  summarise(accuracy = mean(response_correct)) %>%
  mutate(exclude = case_when(
    accuracy < 0.85 ~ "Yes",
    TRUE ~ "No"
  )) %>% 
  filter(exclude == 'Yes')

maze_data <- maze_data[!(maze_data$workerid %in% maze_exclusion$workerid),]
```

We all want to filter out all trials in which the reading time for the critical item was more than 2.5 standard deviations from the mean reading time on that lexical item across all participants. 

```{r}
maze_data <- maze_data %>%
  group_by(trial_id) %>%
  mutate(id_mean = mean(log(rt))) %>%
  mutate(exclusion = (log(rt) < mean(log(rt)) - 2*sd(log(rt))|(log(rt) > mean(log(rt)) + 2*sd(log(rt))))) %>%
  ungroup() %>%
  filter(exclusion==FALSE)
```

```{r}
maze_data <- maze_data %>%
  filter(!is.na(subject_information.age)) %>%
  filter(!is.na(subject_information.party_alignment))
```

### Additional Information

```{r}
gender_transcendence_cols <- c('subject_information.gender_q1','subject_information.gender_q2','subject_information.gender_q3','subject_information.gender_q4','subject_information.gender_q5')

gender_linked_cols <- c('subject_information.gender_q6','subject_information.gender_q7','subject_information.gender_q8','subject_information.gender_q9','subject_information.gender_q10','subject_information.gender_q11','subject_information.gender_q12','subject_information.gender_q13')
```
<br>
Now we can use the mutate() method on <b>maze_data</b> to add two new columns, one for each subscale. We tell R to take the means of the specified columns in [column_names] of <b>maze_data</b> for each individual row: rowMeans(maze_data[column_names]). We also have to subtract this mean from 100 in the case of the <i>'Gender Transcendent'</i> subscale, since it is inversely scored. Finally, we can create an average total score regardless of subscores, simply by meaning the two subscores we already have.

```{r}
maze_data <- maze_data %>%
  mutate(gender_trans = 100 - (rowMeans(maze_data[gender_transcendence_cols]))) %>%
  mutate(gender_link = rowMeans(maze_data[gender_linked_cols])) 

gender_all = c('gender_trans','gender_link')

maze_data <- maze_data %>%
  mutate(gender_total = rowMeans(maze_data[gender_all]))
```

<br>
We also want to add whether the trial included a female or male referent (but also, like, destroy the binary!). In order to do this, we'll just add a <b>trial_gender</b> column that says <i>'female'</i> if the condition was either <i>'neutral_female'</i> or <i>'congruent_female'</i>. Otherwise, we want the <b>trial_gender</b> to say <i>'male'</i>.

```{r}
maze_data <- maze_data %>%
  mutate(trial_gender = case_when(
    condition == "neutral_female" | condition == "congruent_female" ~ "female",
    TRUE ~ "male"
  ) )
```


### Orthographic Length

```{r}
maze_data <- maze_data %>%
  mutate(form_length = str_length(form))

maze_residual_model <- lm(log(rt)~form_length, data = maze_data)

maze_data <- maze_data %>%
  mutate(resid_rt = resid(maze_residual_model))
```

```{r}
maze_data <- maze_data %>%
  mutate(trial_congruency = case_when(
    condition == "congruent_male" | condition == "congruent_female" ~ "congruent",
    TRUE ~ "neutral"
  ))
```

<br>
Finally, we can classify participants by their particular political alignment; we can construe this broadly as "Republicans" vs. "Democrats", with those who placed themselves in the middle as "Non-Partisan".

```{r}
maze_data <- maze_data %>%
  mutate(poli_party = case_when(
    subject_information.party_alignment == 1 | subject_information.party_alignment == 2 ~ "Republican",
    subject_information.party_alignment == 4 | subject_information.party_alignment == 5 ~ "Democrat",
    TRUE ~ "Non-Partisan"
  ))
```

### Joining

```{r}
final_maze <- left_join(maze_data,frequency,by="form")
```


### Model   Scaling

```{r}
final_maze <- final_maze %>%
  mutate(trial_congruency = as.factor(trial_congruency)) %>%
  mutate(trial_congruency = fct_relevel(trial_congruency,"neutral")) %>%
  mutate(trial_gender = as.factor(trial_gender)) %>%
  mutate(c_gender_total = scale(gender_total,scale=FALSE)) %>%
  mutate(c_gender_trans = scale(gender_trans,scale=FALSE)) %>%
  mutate(c_gender_link = scale(gender_link,scale=FALSE)) %>%
  mutate(c_trial_gender = scale(as.numeric(trial_gender),scale=FALSE)) %>%
  mutate(c_trial_congruency = scale(as.numeric(trial_congruency),scale=FALSE)) %>% 
  mutate(young_old = ifelse(subject_information.age > 40,"old","young")) 
```


### Model

```{r}
ultimate_model_unmutated <- lmer(resid_rt~gender_total:subject_information.age + log_all*poli_party*subject_information.age + gender_total:poli_party + trial_gender + gender_total + (1 |workerid) + (1|lexeme),data=final_maze)
```

```{r}
summary(ultimate_model_unmutated)
```


```{r}
maze_data %>%
  filter(!is.na(poli_party)) %>%
  group_by(gender_total,workerid,trial_gender,poli_party,condition) %>%
  summarise(meanrt = mean(resid_rt)) %>%
  ggplot(aes(x=gender_total,y=meanrt,color=trial_gender)) + 
  geom_point() + 
  geom_smooth(method='lm') + 
  scale_color_manual(values = bran_palette) + 
  facet_grid(condition~poli_party) + 
  labs(x="Gender Ideology", y="Mean Reading Time (residual)")
```

```{r}
final_maze %>%
  filter(!is.na(poli_party)) %>%
  filter(!is.na(young_old)) %>%
  group_by(form,poli_party,young_old) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_all > -5) %>%
  ggplot(aes(x=log_all,y=resid_rt_mean)) +
  geom_point() + 
  geom_smooth(method="lm") +
  facet_grid(young_old~poli_party) + 
  labs(x="Unigram Surprisal",y="Mean Reading Time (Residual)") + 
  theme(text=element_text(size=14))
```

# All Data Section

```{r}
maze_data_all <- read.csv('maze_data.csv') %>%
  filter(trial_id!= 'example') 
```

**Exclusions** 

```{r}
maze_data_all <- maze_data_all[!(maze_data_all$workerid %in% maze_exclusion$workerid),]
```

We all want to filter out all trials in which the reading time for the critical item was more than 2.5 standard deviations from the mean reading time on that lexical item across all participants. 

```{r}
maze_data_all <- maze_data_all %>%
  group_by(trial_id) %>%
  mutate(id_mean = mean(log(rt))) %>%
  mutate(exclusion = (log(rt) < mean(log(rt)) - 2*sd(log(rt))|(log(rt) > mean(log(rt)) + 2*sd(log(rt))))) %>%
  ungroup() %>%
  filter(exclusion==FALSE)
```

```{r}
maze_data_all <- maze_data_all %>%
  filter(!is.na(subject_information.age)) %>%
  filter(!is.na(subject_information.party_alignment))
```

**Additional Information**
Now that we have only the rows we want, let's add some new columns, which will contain important information for each data point. Here, we will be adding:

- Gender Ideology Subscores
- Trial Genders
- Trial Morphology Types
- Critical Item Length & Length-Controlled Residuals
- Trial Congruency 
- Partipant Political Affiliation

Ideally, I would've added all of these but the first when I actually created the stimuli and logged responses, but I forgot to! Luckily, R allows us to do this post-hoc fairly straightforwardly... which is good, since these features will be critical in our data visualization and analysis.<br>
<br>

<br>
The question under investigation here is whether or not individuals' conceptions of gender affect how they process  gendered and gender-neutral forms of English personal and professional titles. <br>
<br>
In order to examine this, we need to quanify participants' ideological views! Here we have adopted the 13-item Social Roles Questionnaire put forth in Baber & Tucker (2006). Questions 1-5 correlate to the <i>'Gender Transcendent'</i> subscale, and questions 6-13 correspond to the <i>'Gender Linked'</i> subscale. Each item is scored on a scale of 0-100. So, the first thing we want to do is make two lists of columns which correspond to these two subscales, since the questions are stored individually in the data:

<br>
Now we can use the mutate() method on <b>maze_data</b> to add two new columns, one for each subscale. We tell R to take the means of the specified columns in [column_names] of <b>maze_data</b> for each individual row: rowMeans(maze_data[column_names]). We also have to subtract this mean from 100 in the case of the <i>'Gender Transcendent'</i> subscale, since it is inversely scored. Finally, we can create an average total score regardless of subscores, simply by meaning the two subscores we already have.

```{r}
maze_data_all <- maze_data_all %>%
  mutate(gender_trans = 100 - (rowMeans(maze_data_all[gender_transcendence_cols]))) %>%
  mutate(gender_link = rowMeans(maze_data_all[gender_linked_cols])) 

gender_all = c('gender_trans','gender_link')

maze_data_all <- maze_data_all %>%
  mutate(gender_total = rowMeans(maze_data_all[gender_all]))
```

<br>
We also want to add whether the trial included a female or male referent (but also, like, destroy the binary!). In order to do this, we'll just add a <b>trial_gender</b> column that says <i>'female'</i> if the condition was either <i>'neutral_female'</i> or <i>'congruent_female'</i>. Otherwise, we want the <b>trial_gender</b> to say <i>'male'</i>.

```{r}
maze_data_all <- maze_data_all %>%
  mutate(trial_gender = case_when(
    condition == "neutral_female" | condition == "congruent_female" ~ "female",
    TRUE ~ "male"
  ) )

maze_data_all %>%
  select(workerid,rt,condition,trial_id,trial_gender)
```

<br>
Now we want to add whether or not the lexeme's neutral form is developed by compounding (as in <i>'congress-person'</i>) or by the adoption of the male form (as in <i>'actor'</i> being used more for both men and women). In this study, we only have six lexemes of the latter type, so we'll just tell R to assign those a <b>morph_type</b> value of <i>'adoption'</i> (for 'male adoption'), and all else will be assigned a value of <i>'compound'</i>.

```{r}
maze_data_all <- maze_data_all%>%
  mutate(morph_type = case_when(
    lexeme %notin% ad_lexemes ~ "compound",
    TRUE ~ "adoption"
  ))

maze_data_all %>%
  select(rt,lexeme,morph_type)
```


<br>
Another important factor we want to explore is the length of the critical item! In order to add this, we simply create a new column <b>form_length</b> and tell R to input as that column's value the length of the string that appears in that row's <b>form</b> column, which corresponds to the orthograpic form of the critical item in that trial. <i>Note that this will include spaces in the count!</i>

```{r}
maze_data_all <- maze_data_all %>%
  mutate(form_length = str_length(form))

maze_residual_model <- lm(log(rt)~form_length, data = maze_data_all)

maze_data_all <- maze_data_all %>%
  mutate(resid_rt = resid(maze_residual_model))
```

Now that we have these, we can run a simple linear regression which will show us the effect of orthographic length on reading time. Then we add a new column in the data which is the residual reading time, or the reading time in log space AFTER we control for the effects of orthographic length.

<br>
We also want to make sure we have a column which records whether or not the trial was gender-congruent (as in <i>'Shelby is a congresswoman'</i>) or gender neutral (as in <i>'Shelby is a congressperson'</i>). We add a <b>trial_congruency</b> column, which is valued as <i>'congruent'</i> if that row's condition is one of the two congruent conditions. Otherwise, it gets valued as <i>'neutral'</i>.

```{r}
maze_data_all <- maze_data_all %>%
  mutate(trial_congruency = case_when(
    condition == "congruent_male" | condition == "congruent_female" ~ "congruent",
    TRUE ~ "neutral"
  ))
```

<br>
Finally, we can classify participants by their particular political alignment; we can construe this broadly as "Republicans" vs. "Democrats", with those who placed themselves in the middle as "Non-Partisan".

```{r}
maze_data_all <- maze_data_all %>%
  mutate(poli_party = case_when(
    subject_information.party_alignment == 1 | subject_information.party_alignment == 2 ~ "Republican",
    subject_information.party_alignment == 4 | subject_information.party_alignment == 5 ~ "Democrat",
    TRUE ~ "Non-Partisan"
  ))
```

```{r}
maze_data_all %>% 
  filter(trial_congruency == "neutral") %>% 
  filter(poli_party != "Non-Partisan") %>% 
  group_by(word_idx,poli_party) %>%
  summarize(MeanRT = mean(resid_rt), CI.Low = ci.low(resid_rt), CI.High = ci.high(resid_rt)) %>%
  mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High) %>%
  ggplot(aes(x=word_idx,y=MeanRT, color = poli_party)) +
  geom_point() +
  geom_line() + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=.25) + 
  scale_color_manual(values=bran_palette) + 
  labs(x="Word on screen",y="Mean Reading Time",color="Participant Political Party") + 
  scale_x_continuous(labels=c("[NAME]","is","a(n)","[TITLE]","from","[STATE].","s/he","likes","[ACTIVITY]"), breaks=0:8)
```
