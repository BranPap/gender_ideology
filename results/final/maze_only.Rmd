---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(lme4)
library(ggpubr)

source("helpers.R")
```

```{r}
bran_palette = c("#7ae7e5","#B2A6DE", "#fe5f55", "#14342b", "#69385c")

theme_set(theme_minimal())
```

```{r}
lex_freqs <- read.csv("freq_preped.csv") %>%
  mutate(left_surprisal = (-log(mean_left_neutral))/(-log(mean_left_gendered))) %>%
  mutate(right_surprisal = (-log(mean_right_neutral))/(-log(mean_right_gendered)))
```

```{r}
gender_transcendence_cols <- c('subject_information.gender_q1','subject_information.gender_q2','subject_information.gender_q3','subject_information.gender_q4','subject_information.gender_q5')

gender_linked_cols <- c('subject_information.gender_q6','subject_information.gender_q7','subject_information.gender_q8','subject_information.gender_q9','subject_information.gender_q10','subject_information.gender_q11','subject_information.gender_q12','subject_information.gender_q13')
```

**Data Read-in**

```{r}
maze_data <- read.csv('maze_data.csv') %>%
  filter(trial_id!= 'example') %>%
  filter(region=='critical')
```

```{r}
maze_data %>%
  group_by(workerid) %>%
  summarise(workerid=paste(unique(workerid))) %>%
  nrow()
```


**Running Exclusion Criteria**
Now, we want to exclude any participants who failed to answer at least 80% of the attention check questions correctly. We do this by creating a list of all participants who scored less than 80% on these checks, and then cross-referencing this list with all data points, removing any data points whose participants were in the exclusion list. 

```{r}
maze_exclusion <- maze_data %>% group_by(workerid) %>%
  summarise(accuracy = mean(response_correct)) %>%
  mutate(exclude = ifelse(accuracy < 0.80,'Yes','No')) %>% 
  filter(exclude == 'Yes')

maze_data <- maze_data[!(maze_data$workerid %in% maze_exclusion$workerid),] %>%
  filter(rt !='null')
```

```{r}
maze_data <- maze_data %>%
  group_by(trial_id) %>%
  mutate(id_mean = mean(log(rt))) %>%
  mutate(exclusion = (log(rt) < mean(log(rt)) - 2*sd(log(rt))|(log(rt) > mean(log(rt)) + 2*sd(log(rt))))) %>%
  ungroup() %>%
  filter(exclusion==FALSE)
```


**Additional Information**

```{r}
maze_data <- maze_data %>%
  mutate(gender_trans = 100 - (rowMeans(maze_data[gender_transcendence_cols]))) %>%
  mutate(gender_link = rowMeans(maze_data[gender_linked_cols])) 

gender_all = c('gender_trans','gender_link')

maze_data <- maze_data %>%
  mutate(gender_total = rowMeans(maze_data[gender_all]))
```


### Adding Gender
<br>
We also want to add whether the trial included a female or male referent (but also, like, destroy the binary!). In order to do this, we'll just add a <b>trial_gender</b> column that says <i>'female'</i> if the condition was either <i>'neutral_female'</i> or <i>'congruent_female'</i>. Otherwise, we want the <b>trial_gender</b> to say <i>'male'</i>.

```{r}
maze_data <- maze_data %>%
  mutate(trial_gender = ifelse(condition=='neutral_female' | condition == 'congruent_female','female','male'))

maze_data %>%
  select(workerid,rt,condition,trial_id,trial_gender)
```

### Adding Morphology Type
<br>
Now we want to add whether or not the lexeme's neutral form is developed by compounding (as in <i>'congress-person'</i>) or by the adoption of the male form (as in <i>'actor'</i> being used more for both men and women). In this study, we only have six lexemes of the latter type, so we'll just tell R to assign those a <b>morph_type</b> value of <i>'adoption'</i> (for 'male adoption'), and all else will be assigned a value of <i>'compound'</i>.

```{r}
maze_data <- maze_data%>%
  mutate(morph_type = ifelse(lexeme!= 'actor' & lexeme!= 'host' & lexeme !='hunter' & lexeme!= 'villain' & lexeme!= 'heir' & lexeme!= 'hero','compound','adoption'))

maze_data %>%
  select(rt,lexeme,morph_type)
```


### Adding Form Length & Length-Controlled Residuals
<br>
Another important factor we want to explore is the length of the critical item! In order to add this, we simply create a new column <b>form_length</b> and tell R to input as that column's value the length of the string that appears in that row's <b>form</b> column, which corresponds to the orthograpic form of the critical item in that trial. <i>Note that this will include spaces in the count!</i>

```{r}
maze_data <- maze_data %>%
  mutate(form_length = str_length(form))

simple_model <- lm(log(rt)~form_length, data = maze_data)

maze_data <- maze_data %>%
  mutate(resid_rt = resid(simple_model))
```

```{r}
summary(simple_model)
```


Now that we have these, we can run a simple linear regression which will show us the effect of orthographic length on reading time. Then we add a new column in the data which is the residual reading time, or the reading time in log space AFTER we control for the effects of orthographic length.

### Adding Congruency Column
<br>
We also want to make sure we have a column which records whether or not the trial was gender-congruent (as in <i>'Shelby is a congresswoman'</i>) or gender neutral (as in <i>'Shelby is a congressperson'</i>). We add a <b>trial_congruency</b> column, which is valued as <i>'congruent'</i> if that row's condition is one of the two congruent conditions. Otherwise, it gets valued as <i>'neutral'</i>.

```{r}
maze_data <- maze_data %>%
  mutate(trial_congruency = ifelse(condition=='congruent_male' | condition == 'congruent_female','congruent','neutral'))
```

### Adding Large Political Macrocategories
<br>
Finally, we can classify participants by their particular political alignment; we can construe this broadly as "Republicans" vs. "Democrats", with those who declined to state a preference, or placed themselves in the middle, as "Non-Partisan".

```{r}
maze_data <- maze_data %>%
  mutate(poli_party = ifelse(subject_information.party_alignment == 1 | subject_information.party_alignment == 2,'Republican',ifelse(subject_information.party_alignment == 4 | subject_information.party_alignment == 5,'Democrat','Non-Partisan')))
```

```{r}
maze_data_means_all <- maze_data %>%
  filter(!is.na(poli_party)) %>%
  group_by(condition,workerid,poli_party,gender_total) %>%
  summarise(condition_mean = mean(resid_rt)) 
```

**Visualisations**

```{r}
maze_data_means_all %>%
  filter(!is.na(poli_party)) %>%
  #filter(poli_party != "Non-Partisan") %>%
  group_by(condition,poli_party) %>%
  summarize(mean_rt = mean(condition_mean), CI.Low = ci.low(condition_mean), CI.High = ci.high(condition_mean)) %>%
  mutate(YMin = mean_rt - CI.Low, YMax = mean_rt + CI.High) %>%
  ggplot(aes(x=poli_party,y=mean_rt,color=poli_party)) + 
  geom_point() + 
  geom_point(data=maze_data_means_all, aes(x=poli_party,y=condition_mean),alpha=0.15, position="jitter") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25) + 
  facet_wrap(~ condition) + 
  theme_bw() + 
  labs(x="Participant Political Party", y="Residual Reading Time") + 
  theme(text=element_text(size=16)) + 
  theme(axis.text.x = element_text(angle=5, vjust = .7)) + 
  scale_color_manual(values = bran_palette) +
  theme(legend.position = "none")
```

```{r}
maze_data_means_all %>%
  filter(!is.na(poli_party)) %>%
  #filter(poli_party != "Non-Partisan") %>%
  group_by(condition,poli_party) %>%
  summarize(mean_rt = mean(condition_mean), CI.Low = ci.low(condition_mean), CI.High = ci.high(condition_mean)) %>%
  mutate(YMin = mean_rt - CI.Low, YMax = mean_rt + CI.High) %>%
  ggplot(aes(x=condition,y=mean_rt,color=condition)) + 
  geom_point() + 
  geom_point(data=maze_data_means_all, aes(x=condition,y=condition_mean),alpha=0.15, position="jitter") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25) + 
  facet_wrap(~ poli_party) + 
  theme_bw() + 
  labs(x="Trial Condition", y="Residual Reading Time") + 
  theme(text=element_text(size=16)) + 
  theme(axis.text.x = element_text(angle=90, vjust = .7)) + 
  scale_color_manual(values = bran_palette) +
  theme(legend.position = "none")
```

# With All Regions

**Data Read-in**

```{r}
maze_data_comp <- read.csv('maze_data.csv') %>%
  filter(region=="none")
```

```{r}
maze_data_comp %>%
  group_by(workerid) %>%
  summarise(workerid=paste(unique(workerid))) %>%
  nrow()
```


**Running Exclusion Criteria**
Now, we want to exclude any participants who failed to answer at least 80% of the attention check questions correctly. We do this by creating a list of all participants who scored less than 80% on these checks, and then cross-referencing this list with all data points, removing any data points whose participants were in the exclusion list. 

```{r}
maze_exclusion <- maze_data_comp %>% group_by(workerid) %>%
  summarise(accuracy = mean(response_correct)) %>%
  mutate(exclude = ifelse(accuracy < 0.80,'Yes','No')) %>% 
  filter(exclude == 'Yes')

maze_data_comp <- maze_data_comp[!(maze_data_comp$workerid %in% maze_exclusion$workerid),] %>%
  filter(rt !='null')
```

```{r}
maze_data_comp <- maze_data_comp %>%
  group_by(trial_id) %>%
  mutate(id_mean = mean(log(rt))) %>%
  mutate(exclusion = (log(rt) < mean(log(rt)) - 2*sd(log(rt))|(log(rt) > mean(log(rt)) + 2*sd(log(rt))))) %>%
  ungroup() %>%
  filter(exclusion==FALSE)
```


**Additional Information**

```{r}
maze_data_comp <- maze_data_comp %>%
  mutate(gender_trans = 100 - (rowMeans(maze_data_comp[gender_transcendence_cols]))) %>%
  mutate(gender_link = rowMeans(maze_data_comp[gender_linked_cols])) 

gender_all = c('gender_trans','gender_link')

maze_data_comp <- maze_data_comp %>%
  mutate(gender_total = rowMeans(maze_data_comp[gender_all]))
```


### Adding Gender
<br>
We also want to add whether the trial included a female or male referent (but also, like, destroy the binary!). In order to do this, we'll just add a <b>trial_gender</b> column that says <i>'female'</i> if the condition was either <i>'neutral_female'</i> or <i>'congruent_female'</i>. Otherwise, we want the <b>trial_gender</b> to say <i>'male'</i>.

```{r}
maze_data_comp <- maze_data_comp %>%
  mutate(trial_gender = ifelse(condition=='neutral_female' | condition == 'congruent_female','female','male'))

maze_data_comp %>%
  select(workerid,rt,condition,trial_id,trial_gender)
```

### Adding Morphology Type
<br>
Now we want to add whether or not the lexeme's neutral form is developed by compounding (as in <i>'congress-person'</i>) or by the adoption of the male form (as in <i>'actor'</i> being used more for both men and women). In this study, we only have six lexemes of the latter type, so we'll just tell R to assign those a <b>morph_type</b> value of <i>'adoption'</i> (for 'male adoption'), and all else will be assigned a value of <i>'compound'</i>.

```{r}
maze_data_comp <- maze_data_comp%>%
  mutate(morph_type = ifelse(lexeme!= 'actor' & lexeme!= 'host' & lexeme !='hunter' & lexeme!= 'villain' & lexeme!= 'heir' & lexeme!= 'hero','compound','adoption'))

maze_data_comp %>%
  select(rt,lexeme,morph_type)
```


### Adding Form Length & Length-Controlled Residuals
<br>
Another important factor we want to explore is the length of the critical item! In order to add this, we simply create a new column <b>form_length</b> and tell R to input as that column's value the length of the string that appears in that row's <b>form</b> column, which corresponds to the orthograpic form of the critical item in that trial. <i>Note that this will include spaces in the count!</i>

```{r}
maze_data_comp <- maze_data_comp %>%
  mutate(form_length = str_length(form))

simple_model <- lm(log(rt)~form_length, data = maze_data_comp)

maze_data_comp <- maze_data_comp %>%
  mutate(resid_rt = resid(simple_model))
```

```{r}
summary(simple_model)
```


Now that we have these, we can run a simple linear regression which will show us the effect of orthographic length on reading time. Then we add a new column in the data which is the residual reading time, or the reading time in log space AFTER we control for the effects of orthographic length.

### Adding Congruency Column
<br>
We also want to make sure we have a column which records whether or not the trial was gender-congruent (as in <i>'Shelby is a congresswoman'</i>) or gender neutral (as in <i>'Shelby is a congressperson'</i>). We add a <b>trial_congruency</b> column, which is valued as <i>'congruent'</i> if that row's condition is one of the two congruent conditions. Otherwise, it gets valued as <i>'neutral'</i>.

```{r}
maze_data_comp <- maze_data_comp %>%
  mutate(trial_congruency = ifelse(condition=='congruent_male' | condition == 'congruent_female','congruent','neutral'))
```

### Adding Large Political Macrocategories
<br>
Finally, we can classify participants by their particular political alignment; we can construe this broadly as "Republicans" vs. "Democrats", with those who declined to state a preference, or placed themselves in the middle, as "Non-Partisan".

```{r}
maze_data_comp <- maze_data_comp %>%
  mutate(poli_party = ifelse(subject_information.party_alignment == 1 | subject_information.party_alignment == 2,'Republican',ifelse(subject_information.party_alignment == 4 | subject_information.party_alignment == 5,'Democrat','Non-Partisan')))
```

```{r}
maze_data_comp_means_all <- maze_data_comp %>%
  filter(!is.na(poli_party)) %>%
  group_by(condition,workerid,poli_party,gender_total) %>%
  summarise(condition_mean = mean(resid_rt)) 
```

**Visualisations**

```{r}
maze_data_comp_means_all %>%
  filter(!is.na(poli_party)) %>%
  #filter(poli_party != "Non-Partisan") %>%
  group_by(condition,poli_party) %>%
  summarize(mean_rt = mean(condition_mean), CI.Low = ci.low(condition_mean), CI.High = ci.high(condition_mean)) %>%
  mutate(YMin = mean_rt - CI.Low, YMax = mean_rt + CI.High) %>%
  ggplot(aes(x=poli_party,y=mean_rt,color=poli_party)) + 
  geom_point() + 
  geom_point(data=maze_data_comp_means_all, aes(x=poli_party,y=condition_mean),alpha=0.15, position="jitter") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25) + 
  facet_wrap(~ condition) + 
  theme_bw() + 
  labs(x="Participant Political Party", y="Residual Reading Time") + 
  theme(text=element_text(size=16)) + 
  theme(axis.text.x = element_text(angle=5, vjust = .7)) + 
  scale_color_manual(values = bran_palette) +
  theme(legend.position = "none")
```
```{r}
ggsave("maze_all_regions_party.png", width=7, height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
```


```{r}
maze_data_comp_means_all %>%
  filter(!is.na(poli_party)) %>%
  #filter(poli_party != "Non-Partisan") %>%
  group_by(condition,poli_party) %>%
  summarize(mean_rt = mean(condition_mean), CI.Low = ci.low(condition_mean), CI.High = ci.high(condition_mean)) %>%
  mutate(YMin = mean_rt - CI.Low, YMax = mean_rt + CI.High) %>%
  ggplot(aes(x=condition,y=mean_rt,color=condition)) + 
  geom_point() + 
  geom_point(data=maze_data_comp_means_all, aes(x=condition,y=condition_mean),alpha=0.15, position="jitter") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25) + 
  facet_wrap(~ poli_party) + 
  theme_bw() + 
  labs(x="Trial Condition", y="Residual Reading Time") + 
  theme(text=element_text(size=16)) + 
  theme(axis.text.x = element_text(angle=90, vjust = .7)) + 
  scale_color_manual(values = bran_palette) +
  theme(legend.position = "none")
```

```{r}
ggsave("maze_all_regions_condition.png", width=7, height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
```

```{r}
model <- lmer(resid_rt~poli_party + subject_information.age + condition + (1|name) + (1|lexeme) + (1|workerid),data=maze_data)
```

```{r}
summary(model)
```

