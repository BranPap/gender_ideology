---
title: "Sally the Congressperson: A Psycho- and Sociolinguistic Investigation into the Relationship Between Ideology, Gender, and Language"
author: "B. Papineau"
date: "Autumn 2021"
output:
  html_notebook:
    toc: yes
    toc_float:
      collapsed: no
    number_sections: yes
    theme: journal
  html_document:
    toc: yes
    df_print: paged
---

# Introduction 
The code and information contained herein constitutes the complete write-up of the experiments I carried out for my first Qualifying Paper towards the PhD in Linguistics at Stanford University. The goal is to make this document both a dumping ground for my ideas while it is in progress, as well as, eventually, a publicly-available version of my Qualifying Paper, in the spirit of Open Science.

## Preliminaries 

### Setting up the Notebook

For this write-up and analysis, I require the following packages, loaded in here:

```{r echo=TRUE}
library(ggplot2) 
library(tidyverse) 
library(lme4) 
library(stringr)
library(languageR)
library(lmerTest)
library(reshape2)
library(grid)

source("helpers.R")
```

I also use a custom color palette, so I include the code for that here as well^[It is my hope and intention that this color palette be color-blind friendly. If you have accessibility concerns, please do not hesitate to reach out to me!].

```{r}
bran_palette = c("#7ae7e5", "#fe5f55", "#B2A6DE", "#14342b", "#69385c")

theme_set(theme_minimal())
```

### Frequency Data

We also need the frequency data!

```{r}
frequency <- read.csv("freq_vals.csv")
```

```{r}
lib_cols <- c('ABC','CNN','PBS','NBC','MSNBC','NPR','CBS')
```

```{r}
frequency <- frequency %>%
  mutate(total_left = rowSums(frequency[lib_cols])) %>%
  mutate(total_right = FOX) %>%
  mutate(all_wpm = ((total_left + total_right) / 121500000) * 1000000) %>%
  mutate(left_wpm = (total_left/109300000) * 1000000) %>%
  mutate(right_wpm = (total_right/12200000) * 1000000) %>%
  mutate(neutral_binary = ifelse(gender=="neutral",1,0)) %>%
  mutate(morph_type = ifelse(lexeme!= 'actor' & lexeme!= 'host' & lexeme !='hunter' & lexeme!= 'villain' & lexeme!= 'heir' & lexeme!= 'hero','compound','adoption')) 
```

```{r}
frequency <- frequency %>%
  group_by(word) %>%
  summarise(mean_freq_left = mean(left_wpm), mean_freq_right = mean(right_wpm), mean_freq_all = mean(all_wpm)) %>%
  rename(form = word)
```

Re-write frequency to avoid zero numbers!

```{r}
frequency[frequency == 0.00000000] <- 0.0001
```

Take log frequency of each media type.

```{r}
frequency <- frequency %>%
  mutate(log_right = log(mean_freq_right), log_left = log(mean_freq_left), log_all = log(mean_freq_all)) 
```

Create media difference 

```{r}
frequency <- frequency %>% 
  mutate(media_diff = log_left - log_right) %>%
  mutate(nonexistent = ifelse(media_diff == 0 & log_left < -4,"true","false"))
```

### Norming Data

And here is the norming data values:

```{r ECHO=TRUE}
norming_data <- read.csv("norming_data.csv") %>%
  filter(id!="example1") %>% # Will filter out non-critical trials, i.e. the example trial from the beginning of the experiment
  mutate(equalized_response = ifelse(scale=="FM",8-response,response)) %>% # This will render all data points on the same scale, as participants randomly received either "very likely a man" or "very likely a woman" as the left end of their response scale, with the other appearing at the right end
  mutate(orthog = ifelse(orthog=="sroceress","sorceress",orthog)) %>% # Fixes a typo
  mutate(id = ifelse(id=="Stunt_double","stunt double",id)) %>% # This, as well as all lines below it, convert compounds formed by spaces from their underscore forms to their spaced forms (e.g. police_officer -> Police officer)
  mutate(id = ifelse(id=="Police_officer","police officer",id)) %>%
  mutate(id = ifelse(id=="Flight_attendant","flight attendant",id)) %>%
  mutate(id = ifelse(id=="Anchor","anchor",id)) %>%
  mutate(id = ifelse(id=="Businessperson","businessperson",id)) %>%
   mutate(id = ifelse(id=="Camera","camera operator",id)) %>%
  mutate(id = ifelse(id=="Congressperson","congressperson",id)) %>%
  mutate(id = ifelse(id=="Craftsperson","craftsperson",id)) %>%
  mutate(id = ifelse(id=="Crewmember","crewmember",id)) %>%
  mutate(id = ifelse(id=="Firefighter","firefighter",id)) %>%
  mutate(id = ifelse(id=="Foreperson","foreperson",id)) %>%
  mutate(id = ifelse(id=="Layperson","layperson",id)) %>%
  mutate(id = ifelse(id=="Meteorologist","meteorologist",id)) %>%
  mutate(id = ifelse(id=="Salesperson","salesperson",id)) %>%
  mutate(id = ifelse(id=="Actor","actor",id)) %>%
  mutate(id = ifelse(id=="Heir","heir",id)) %>%
  mutate(id = ifelse(id=="Hero","hero",id)) %>%
  mutate(id = ifelse(id=="Host","host",id)) %>%
  mutate(id = ifelse(id=="Hunter","hunter",id)) %>%
  mutate(id = ifelse(id=="Villain","villain",id)) %>%
  mutate(orthog = ifelse(orthog=="airline steward","steward",orthog)) %>%
  mutate(orthog = ifelse(orthog=="airline stewardess","stewardess",orthog))
```

```{r ECHO=TRUE}
norming_exclusion <- norming_data %>% 
  filter(gender=="female") %>% 
  group_by(workerid) %>%
  summarize(female_mean = mean(equalized_response)) %>%
  unique() %>% 
  mutate(exclusion = female_mean < mean(female_mean) - 2*sd(female_mean)) %>%
  filter(exclusion==TRUE)
```

```{r ECHO=TRUE}
norming_data <- norming_data[!(norming_data$workerid %in% norming_exclusion$workerid),]
```

```{r}
norming_means <- norming_data %>%
  filter(neutral_morh !="male_adoption") %>%
  group_by(orthog,id) %>%
  summarise(indi_mean = mean(equalized_response), trial_count=n()) %>%
  rename(form = orthog) %>%
  rename(lexeme =id)
```

```{r}
norming_adoptions <- norming_data %>%
  filter(neutral_morh == "male_adoption") %>%
  group_by(orthog) %>%
  summarise(indi_mean = mean(equalized_response), trial_count=n()) %>%
  mutate(lexeme = ifelse(orthog=="actress","actor",ifelse(orthog=="heiress","heir",ifelse(orthog=="heroine","hero",ifelse(orthog=="hostess","host",ifelse(orthog=="huntress","hunter",ifelse(orthog=="villainess","villain",orthog))))))) %>%
    rename(form = orthog)
```

```{r}
norming_adoptions <- norming_adoptions[, c("lexeme", "form", "indi_mean", "trial_count")]
```

```{r}
norming_means <- rbind(norming_means,norming_adoptions) %>%
  rename(lexeme_norm = lexeme)
```

```{r include=FALSE}
later_criticals <- c("actor","anchor","businessperson","camera operator","congressperson","craftsperson","crewmember","firefighter","flight attendant","foreperson","heir","hero","host","hunter","layperson","meteorologist","police officer","salesperson","stunt double","villain")
```

```{r include=FALSE}
norming_means <- norming_means[(norming_means$lexeme_norm %in% later_criticals),]
```

**Neutrals Only**

```{r}
norming_means_neutral <- norming_data %>%
  filter(gender=="neutral") %>%
  filter(neutral_morh !="male_adoption") %>%
  group_by(orthog,id) %>%
  summarise(indi_mean = mean(equalized_response), trial_count=n()) %>%
  rename(form = orthog) %>%
  rename(lexeme =id)
```

```{r}
norming_adoptions_neutral <- norming_data %>%
  filter(gender=="neutral") %>%
  filter(neutral_morh == "male_adoption") %>%
  group_by(orthog) %>%
  summarise(indi_mean = mean(equalized_response), trial_count=n()) %>%
  mutate(lexeme = ifelse(orthog=="actress","actor",ifelse(orthog=="heiress","heir",ifelse(orthog=="heroine","hero",ifelse(orthog=="hostess","host",ifelse(orthog=="huntress","hunter",ifelse(orthog=="villainess","villain",orthog))))))) %>%
    rename(form = orthog)
```

```{r}
norming_adoptions_neutral <- norming_adoptions_neutral[, c("lexeme", "form", "indi_mean", "trial_count")]
```

```{r}
norming_means_neutral <- rbind(norming_means_neutral,norming_adoptions_neutral)
```

```{r include=FALSE}
norming_means_neutral <- norming_means_neutral[(norming_means_neutral$lexeme %in% later_criticals),]
```

## Self-Paced Reading Study

### Methods

**Participants**

We originally ran the experiment on 200 participants, recruited through the online participant recruitment platform <a href="https://www.prolific.co">Prolific</a>. The mean time of the experiment was 5.39 minutes, and participants were paid $1.75 for their participation^[This amounts to an hourly rate of \$20.73. We originally anticipated that participants would take an average of 7 minutes to complete the experiment, and set the base pay at \$15 an hour.]. The only restrictions placed on participants were that they:

<ol>
  <li>Were born in the United States</li>
  <li>Lived in the United States at the time of participation</li>
  <li>Spoke English as a first language</li>
  <li>Had not participated in the norming study for the stimuli</li>
</ol>

These requirements were implemented in order to assure that speakers came from at least somewhat similar linguistic backgrounds, as certain lexical items in the study (such as <i>congressperson</i>) are quite localized to the United States.

After this initial run of the experiment, we found that there was a dearth of conservative or Republican-aligned participants. As a result, we ran the experiment again, this time on 98 self-identified Republicans. This was achieved by adding a filter on Prolific so that only Republican-identified individuals could see the task. The rest of the experiment, including payment, was exactly the same, except that an additional disclaimer that participants could not use the FireFox browser experiment, after the first run revealed an incompatibility between JavaScript and FireFox. The two runs of the experiment amounted in a total of 298 participants who completed the task.

### Analysis

**Reading in the Data**

```{r}
sprt_data <- read.csv('sprt_data.csv') %>%
  filter(trial_id!= 'example') %>%
  filter(region=='critical')
```

**Exclusions** 

Now, we want to exclude any participants who failed to answer at least 85% of the attention check questions correctly. We do this by creating a list of all participants who scored less than 85% on these checks, and then cross-referencing this list with all data points, removing any data points whose participants were in the exclusion list. 

```{r}
sprt_exclusion <- sprt_data %>% group_by(workerid) %>%
  summarise(accuracy = mean(response_correct)) %>%
  mutate(exclude = ifelse(accuracy < 0.85,'Yes','No')) %>% 
  filter(exclude == 'Yes')

sprt_data <- sprt_data[!(sprt_data$workerid %in% sprt_exclusion$workerid),]
```

We all want to filter out all trials in which the reading time for the critical item was more than 2.5 standard deviations from the mean reading time on that lexical item across all participants. 

```{r}
sprt_data <- sprt_data %>%
  group_by(trial_id) %>%
  mutate(id_mean = mean(log(rt))) %>%
  mutate(exclusion = (log(rt) < mean(log(rt)) - 2*sd(log(rt))|(log(rt) > mean(log(rt)) + 2*sd(log(rt))))) %>%
  ungroup() %>%
  filter(exclusion==FALSE)
```


sprt_data <- sprt_data %>%
  filter(!is.na(subject_information.age)) %>%
  filter(!is.na(subject_information.poli_party))


This results in 238 trials being removed from the 5580 we got after the by-participant exclusions. We now have 5342 trials we can use for analysis.

**Additional Information**
Now that we have only the rows we want, let's add some new columns, which will contain important information for each data point. Here, we will be adding:

- Gender Ideology Subscores
- Trial Genders
- Trial Morphology Types
- Critical Item Length & Length-Controlled Residuals
- Trial Congruency 
- Partipant Political Affiliation

Ideally, I would've added all of these but the first when I actually created the stimuli and logged responses, but I forgot to! Luckily, R allows us to do this post-hoc fairly straightforwardly... which is good, since these features will be critical in our data visualization and analysis.<br>
<br>

<br>
The question under investigation here is whether or not individuals' conceptions of gender affect how they process  gendered and gender-neutral forms of English personal and professional titles. <br>
<br>
In order to examine this, we need to quanify participants' ideological views! Here we have adopted the 13-item Social Roles Questionnaire put forth in Baber & Tucker (2006). Questions 1-5 correlate to the <i>'Gender Transcendent'</i> subscale, and questions 6-13 correspond to the <i>'Gender Linked'</i> subscale. Each item is scored on a scale of 0-100. So, the first thing we want to do is make two lists of columns which correspond to these two subscales, since the questions are stored individually in the data:

```{r}
gender_transcendence_cols <- c('subject_information.gender_q1','subject_information.gender_q2','subject_information.gender_q3','subject_information.gender_q4','subject_information.gender_q5')

gender_linked_cols <- c('subject_information.gender_q6','subject_information.gender_q7','subject_information.gender_q8','subject_information.gender_q9','subject_information.gender_q10','subject_information.gender_q11','subject_information.gender_q12','subject_information.gender_q13')
```
<br>
Now we can use the mutate() method on <b>sprt_data</b> to add two new columns, one for each subscale. We tell R to take the means of the specified columns in [column_names] of <b>sprt_data</b> for each individual row: rowMeans(sprt_data[column_names]). We also have to subtract this mean from 100 in the case of the <i>'Gender Transcendent'</i> subscale, since it is inversely scored. Finally, we can create an average total score regardless of subscores, simply by meaning the two subscores we already have.

```{r}
sprt_data <- sprt_data %>%
  mutate(gender_trans = 100 - (rowMeans(sprt_data[gender_transcendence_cols]))) %>%
  mutate(gender_link = rowMeans(sprt_data[gender_linked_cols])) 

gender_all = c('gender_trans','gender_link')

sprt_data <- sprt_data %>%
  mutate(gender_total = rowMeans(sprt_data[gender_all]))
```

<br>
We also want to add whether the trial included a female or male referent (but also, like, destroy the binary!). In order to do this, we'll just add a <b>trial_gender</b> column that says <i>'female'</i> if the condition was either <i>'neutral_female'</i> or <i>'congruent_female'</i>. Otherwise, we want the <b>trial_gender</b> to say <i>'male'</i>.

```{r}
sprt_data <- sprt_data %>%
  mutate(trial_gender = ifelse(condition=='neutral_female' | condition == 'congruent_female','female','male')) 

sprt_data %>%
  select(workerid,rt,condition,trial_id,trial_gender)
```

<br>
Now we want to add whether or not the lexeme's neutral form is developed by compounding (as in <i>'congress-person'</i>) or by the adoption of the male form (as in <i>'actor'</i> being used more for both men and women). In this study, we only have six lexemes of the latter type, so we'll just tell R to assign those a <b>morph_type</b> value of <i>'adoption'</i> (for 'male adoption'), and all else will be assigned a value of <i>'compound'</i>.

```{r}
sprt_data <- sprt_data%>%
  mutate(morph_type = ifelse(lexeme!= 'actor' & lexeme!= 'host' & lexeme !='hunter' & lexeme!= 'villain' & lexeme!= 'heir' & lexeme!= 'hero','compound','adoption'))

sprt_data %>%
  select(rt,lexeme,morph_type)
```


<br>
Another important factor we want to explore is the length of the critical item! In order to add this, we simply create a new column <b>form_length</b> and tell R to input as that column's value the length of the string that appears in that row's <b>form</b> column, which corresponds to the orthograpic form of the critical item in that trial. <i>Note that this will include spaces in the count!</i>

```{r}
sprt_data <- sprt_data %>%
  mutate(form_length = str_length(form))

sprt_residual_model <- lm(log(rt)~form_length, data = sprt_data)

sprt_data <- sprt_data %>%
  mutate(resid_rt = resid(sprt_residual_model))
```

Now that we have these, we can run a simple linear regression which will show us the effect of orthographic length on reading time. Then we add a new column in the data which is the residual reading time, or the reading time in log space AFTER we control for the effects of orthographic length.

<br>
We also want to make sure we have a column which records whether or not the trial was gender-congruent (as in <i>'Shelby is a congresswoman'</i>) or gender neutral (as in <i>'Shelby is a congressperson'</i>). We add a <b>trial_congruency</b> column, which is valued as <i>'congruent'</i> if that row's condition is one of the two congruent conditions. Otherwise, it gets valued as <i>'neutral'</i>.

```{r}
sprt_data <- sprt_data %>%
  mutate(trial_congruency = ifelse(condition=='congruent_male' | condition == 'congruent_female','congruent','neutral'))
```

<br>
Finally, we can classify participants by their particular political alignment; we can construe this broadly as "Republicans" vs. "Democrats", with those who declined to state a preference, or placed themselves in the middle, as "Non-Partisan".

```{r}
sprt_data <- sprt_data %>%
  mutate(poli_party = ifelse(subject_information.party_alignment == 1 | subject_information.party_alignment == 2,'Republican',ifelse(subject_information.party_alignment == 4 | subject_information.party_alignment == 5,'Democrat','Non-Partisan')))
```

**Joining independent data**
Now that we have this information, we want to left join our frequency information so that we can use it in later analyses. We begin by adding the norming values' means, of all forms.

```{r}
final_spr <- left_join(sprt_data,norming_means,by="form")
```

Now we can add the frequency data as well, by form. 

```{r}
final_spr <- left_join(final_spr,frequency,by="form")
```

Now we can add additional lexeme-level norming information for the neutral forms, so that we can tackle the question of what role real-world expectations have on processing times. 

```{r}
final_spr <- left_join(final_spr,norming_means_neutral,by="lexeme")
```

```{r}
final_spr <- subset(final_spr, select = -c(form.y,trial_count.y,trial_count.x,error,subject_information.comments,subject_information.asses,subject_information.enjoyment,subject_information.gender_q1,subject_information.gender_q2,subject_information.gender_q3,subject_information.gender_q4,subject_information.gender_q5,subject_information.gender_q6,subject_information.gender_q7,subject_information.gender_q8,subject_information.gender_q9,subject_information.gender_q10,subject_information.gender_q11,subject_information.gender_q12,subject_information.gender_q13,lexeme_norm)) %>%
  rename(form_norm = indi_mean.x, lexeme_norm = indi_mean.y, form = form.x) %>%
  mutate(young_old = ifelse(subject_information.age > 40,"old","young")) %>% 
  mutate(media_source = ifelse(poli_party == "Republican",log_right,ifelse(poli_party == "Democrat",log_left,log_all))) 
```


### Frequencies

```{r}
frequency %>%
  ggplot(aes(x=mean_freq_left,y=mean_freq_right, label=form)) + 
  geom_point() +
  geom_text() + 
  geom_abline(intercept=0,slope=1,color="gray60") +
  coord_fixed(xlim=c(0,250))
```

```{r}
frequency %>%
  filter(mean_freq_right < 50) %>% 
  ggplot(aes(x=mean_freq_left,y=mean_freq_right, label=form)) + 
  geom_point() +
  geom_text() + 
  geom_abline(intercept=0,slope=1,color="gray60") 
```

```{r}
frequency %>%
  ggplot(aes(x=log_left,y=log_right, label=form)) + 
  geom_point() +
  geom_text(size=4,nudge_y=.5) + 
  geom_abline(intercept=0,slope=1,color="gray60") 
```

```{r}
transfer_data <- final_spr %>%
  select(form,trial_gender) %>%
  unique()
```

```{r}
temp <- left_join(frequency,transfer_data, by="form")
```

```{r}
temp <- temp %>%
  mutate(form = fct_reorder(as.factor(form),media_diff)) %>%
   mutate(morph_type = ifelse(form!= 'actor' & form!= 'host' & form !='hunter' & form!= 'villain' & form!= 'heir' & form!= 'hero' & form!= "actress" & form!= "hostess" & form!= "huntress" & form!= "villainess" & form!= "heiress" & form!= "heroine",'compound','adoption')) %>%
  mutate(gender = ifelse(form== 'anchor' | form== 'businessperson'| form== 'camera operator' | form== 'congressperson'| form== 'craftsperson'| form== 'crewmember'| form== 'firefighter'| form== 'flight attendant'| form== 'foreperson'| form== 'layperson'| form== 'meteorologist'| form== 'police officer'| form== 'salesperson'| form== 'stunt double','neutral','gendered')) %>%
  mutate(gender = ifelse(gender == "gendered",as.character(trial_gender),gender)) %>%
  filter(!(trial_gender == "female" & gender=="neutral")) %>%
  filter(!(form=="actor" & gender=="female" | (form=="heir" & gender=="female")| (form=="hero" & gender=="female")| (form=="hunter" & gender=="female")| (form=="heir" & gender=="female")| (form=="host" & gender=="female")| (form=="villain" & gender=="female")))
```

```{r}
temp %>%
  ggplot(aes(x=form, y=media_diff, fill=gender,alpha=morph_type)) + 
  geom_bar(stat="identity") + 
  theme(axis.text.x = element_text(angle=45, hjust = 1, vjust = 1)) + 
  scale_alpha_discrete(range = c(0.5,1))
```


```{r}
final_spr %>%
  ggplot(aes(x=log_all, y=resid_rt, color=trial_gender, linetype=trial_congruency)) + 
  geom_point() + 
  geom_smooth()
```

```{r}
final_spr %>%
  group_by(form,trial_congruency,trial_gender) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  ggplot(aes(x=log_all,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm")
```

```{r}
final_spr %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_all > -5) %>%
  ggplot(aes(x=log_all,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency,label=form,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

```{r}
final_spr %>%
  filter(!is.na(poli_party)) %>%
  group_by(form,trial_congruency,trial_gender,morph_type,poli_party) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_all > -5) %>%
  ggplot(aes(x=log_all,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency,label=form,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=2,nudge_y =.03) + 
  facet_wrap(~poli_party)
```


**log_left, democrats**


```{r}
final_spr %>%
  filter(poli_party == "Democrat") %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_left > -5) %>%
  ggplot(aes(x=log_left,y=resid_rt_mean,label=form)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

```{r}
final_spr %>%
  filter(poli_party == "Democrat") %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_left > -5) %>%
  ggplot(aes(x=log_left,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency,label=form,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

**log_all, democrats**

```{r}
final_spr %>%
  filter(poli_party == "Democrat") %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_left > -5) %>%
  ggplot(aes(x=log_all,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency,label=form,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

**log_right, republicans**

```{r}
final_spr %>%
  filter(poli_party == "Republican") %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_right > -5) %>%
  ggplot(aes(x=log_right,y=resid_rt_mean,label=form)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

```{r}
final_spr %>%
  filter(poli_party == "Republican") %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_right > -5) %>%
  ggplot(aes(x=log_right,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency,label=form,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

**log_all, republicans**

```{r}
final_spr %>%
  filter(poli_party == "Republican") %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_right > -5) %>%
  ggplot(aes(x=log_all,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency,label=form,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

**log_left, republicans**

```{r}
final_spr %>%
  filter(poli_party == "Republican") %>%
  group_by(form,trial_congruency,trial_gender,morph_type) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_right > -5) %>%
  ggplot(aes(x=log_left,y=resid_rt_mean,color=trial_gender,linetype=trial_congruency,label=form,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03)
```

```{r}
cor(final_spr$log_all,final_spr$log_left)
```


```{r}
cor(final_spr$log_all,final_spr$log_right)
```


```{r}
cor(final_spr$log_left,final_spr$log_right)
```


## Preliminary Visualisations

These plots explore single facets along which individual predictions might be made about reading times. 

### Reading Time by Norming 

```{r}
final_spr %>%
  ggplot(aes(x=form_norm,y=resid_rt)) +
  geom_point() + 
  geom_smooth(method='lm')
```
`
```{r}
final_spr %>%
  group_by(form,trial_gender,trial_congruency) %>%
  mutate(mean_resid_rt = mean(resid_rt)) %>%
  ggplot(aes(x=form_norm,y=mean_resid_rt,color=trial_gender,linetype=trial_congruency,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method='lm')
```

```{r}
final_spr %>%
  group_by(form,trial_gender,trial_congruency) %>%
  mutate(mean_resid_rt = mean(resid_rt)) %>%
  ggplot(aes(x=lexeme_norm,y=mean_resid_rt,color=trial_gender,linetype=trial_congruency,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method='lm')
```

```{r}
final_spr %>%
  filter(lexeme != "flight attendant") %>%
  group_by(form,trial_gender,trial_congruency) %>%
  mutate(mean_resid_rt = mean(resid_rt)) %>%
  ggplot(aes(x=lexeme_norm,y=mean_resid_rt,color=trial_gender,linetype=trial_congruency,shape=trial_congruency)) +
  geom_point() + 
  geom_smooth(method='lm')
```

### Reading Time by Frequency

**Left Wing, All Items**

```{r}
final_spr %>%
  ggplot(aes(x=mean_freq_left,y=resid_rt)) +
  geom_point() + 
  geom_smooth(method='lm')
```

**Left Wing, Neutral Items**

```{r}
sanity = final_spr %>%
  filter(trial_congruency=="neutral")
```


```{r}
final_spr %>%
  filter(trial_congruency=="neutral") %>%
  ggplot(aes(x=mean_freq_left,y=resid_rt)) +
  geom_point() + 
  geom_smooth(method='lm')
```

**Right Wing**

```{r}
final_spr %>%
  ggplot(aes(x=mean_freq_right,y=resid_rt)) +
  geom_point() + 
  geom_smooth(method='lm')
```

```{r}
final_spr %>%
  filter(trial_congruency=="neutral") %>%
  ggplot(aes(x=mean_freq_right,y=resid_rt)) +
  geom_point() + 
  geom_smooth(method='lm')
```

### Reading Time by Ideology 

**Gender Total**
```{r}
final_spr %>%
  filter(gender_total < 51) %>%
  ggplot(aes(x=gender_total,y=resid_rt,color=trial_gender,linetype=trial_congruency)) +
  geom_point() + 
  geom_smooth(method='lm') # + 
#  facet_grid(trial_gender~trial_congruency)
```

**Gender Link**
```{r}
final_spr %>%
  filter(trial_congruency == "neutral") %>%
  ggplot(aes(x=gender_link,y=resid_rt)) +
  geom_point() + 
  geom_smooth(method='lm')
```

**Gender Transendence**
```{r}
final_spr %>%
  filter(trial_congruency == "neutral") %>%
  ggplot(aes(x=gender_trans,y=resid_rt)) +
  geom_point() + 
  geom_smooth(method='lm')
```

### Reading Time by Real-World Probabilities 



```{r}
final_spr <- final_spr %>%
  mutate(trial_congruency = as.factor(trial_congruency)) %>%
  mutate(trial_congruency = fct_relevel(trial_congruency,"neutral")) %>%
  mutate(trial_gender = as.factor(trial_gender)) %>%
  mutate(c_gender_total = scale(gender_total,scale=FALSE)) %>%
  mutate(c_gender_trans = scale(gender_trans,scale=FALSE)) %>%
  mutate(c_gender_link = scale(gender_link,scale=FALSE)) %>%
  mutate(c_trial_gender = scale(as.numeric(trial_gender),scale=FALSE)) %>%
  mutate(c_trial_congruency = scale(as.numeric(trial_congruency),scale=FALSE))
```

```{r}
subject_means <- final_spr %>%
  select(workerid,subject_information.party_alignment,gender_link,gender_total,gender_trans) %>%
  unique()
```

```{r}
subject_means_w_party <- final_spr %>%
  select(workerid,subject_information.party_alignment,gender_link,gender_total,gender_trans) %>%
  filter(!is.na(subject_information.party_alignment)) %>%
  unique()
```

## Models

### Model One: Simple

```{r}
model_one <- lmer(resid_rt~gender_total*trial_congruency*trial_gender + (1 |name) + (1|workerid) + (1|lexeme), data=final_spr)
```

```{r}
summary(model_one)
```

### Model Two: Simple model with centered variables

```{r}
model_two <- lmer(resid_rt~c_gender_total*c_trial_congruency*c_trial_gender + (1 |name) + (1|workerid) + (1|lexeme), data=final_spr)
```

```{r}
summary(model_two)
```

### Model Three: Centered Ideology, Centered Trial Congruency, and Centered Trial Gender with Random Slopes and Intercepts for Name, Workerid, and Lexeme

```{r}
model_three <- lmer(resid_rt~c_gender_total*c_trial_congruency*c_trial_gender + (1 + c_gender_total + c_trial_congruency|name) + (1 + c_trial_congruency + c_trial_gender|workerid) + (1 + c_trial_congruency + c_trial_gender|lexeme), data=final_spr)
```

```{r}
summary(model_three)
```

### Model Four
Same as Model 3, but with political orientation (5-point scale) added in without interactions

```{r}
model_four <- lmer(resid_rt~c_gender_total*c_trial_congruency*c_trial_gender + subject_information.party_alignment + (1 + c_gender_total + c_trial_congruency|name) + (1 + c_trial_congruency + c_trial_gender|workerid) + (1 + c_trial_congruency + c_trial_gender|lexeme), data=final_spr)
```

```{r}
summary(model_four)
```

### Model Five: Confirming the Statistical Difference in Ideology between Parties

```{r}
model_five <- lm(gender_total~subject_information.party_alignment, data=subject_means)
```

```{r}
summary(model_five)
```

### Interim: Adding by-subject Ideology Residuals

```{r}
ideo_residuals <- data.frame(
  subject_means_w_party["workerid"],
  ResidIdeo = lm(gender_total~subject_information.party_alignment, data=subject_means_w_party)$resid
)
```

```{r}
final_spr <- left_join(final_spr,ideo_residuals,by="workerid")
```

### Model Six: Residual Ideologies
Same as Model Four but with ResidualIdeologies instead of raw ideology scores

```{r}
model_six <- lmer(resid_rt~ResidIdeo*c_trial_congruency*c_trial_gender + subject_information.party_alignment + (1 + ResidIdeo + c_trial_congruency|name) + (1 + c_trial_congruency + c_trial_gender|workerid) + (1 + c_trial_congruency + c_trial_gender|lexeme), data=final_spr)
```

```{r}
summary(model_six)
```

```{r}
final_spr %>%
  ggplot(aes(x=ResidIdeo,y=resid_rt)) + 
  geom_point() + 
  geom_smooth()
```

### Model Seven
Same as model six, but with added log_all frequency

```{r}
model_seven <- lmer(resid_rt~ResidIdeo*c_trial_congruency*c_trial_gender + subject_information.party_alignment + log_all + (1 + ResidIdeo + c_trial_congruency|name) + (1 + c_trial_congruency + c_trial_gender|workerid) + (1 + c_trial_congruency + c_trial_gender|lexeme), data=final_spr)
```

```{r}
summary(model_seven)
```


### Model Eight
Same as model seven, but with added neutral lexeme-level norms

```{r}
model_eight <- lmer(resid_rt~ResidIdeo*c_trial_congruency*c_trial_gender + subject_information.party_alignment + log_all + lexeme_norm + (1 + ResidIdeo + c_trial_congruency|name) + (1 + c_trial_congruency + c_trial_gender|workerid) + (1 + c_trial_congruency + c_trial_gender|lexeme), data=final_spr)
```

```{r}
summary(model_eight)
```


### Interim: adding residual trans and link subscores

```{r}
trans_residuals <- data.frame(
  subject_means_w_party["workerid"],
  ResidTrans = lm(gender_trans~subject_information.party_alignment, data=subject_means_w_party)$resid
)
```

```{r}
final_spr <- left_join(final_spr,trans_residuals,by="workerid")
```

```{r}
link_residuals <- data.frame(
  subject_means_w_party["workerid"],
  ResidLink = lm(gender_link~subject_information.party_alignment, data=subject_means_w_party)$resid
)
```

```{r}
final_spr <- left_join(final_spr,link_residuals,by="workerid")
```

### Model Nine
Same as model eight, but with gender transendence 

```{r}
model_nine <- lmer(resid_rt~ResidTrans*c_trial_congruency*c_trial_gender + subject_information.party_alignment + log_all + lexeme_norm + (1 + ResidTrans + c_trial_congruency|name) + (1 + c_trial_congruency + c_trial_gender|workerid) + (1 + c_trial_congruency + c_trial_gender|lexeme), data=final_spr)
```

```{r}
summary(model_nine)
```

```{r}
final_spr %>%
  ggplot(aes(x= gender_trans, y=resid_rt)) + 
  geom_point() + 
  geom_smooth(method="lm")
```


### Model Ten
Same as model nine, but with gender link 

```{r}
model_ten <- lmer(resid_rt~ResidLink*c_trial_congruency*c_trial_gender + subject_information.party_alignment + log_all + lexeme_norm + (1 + ResidLink + c_trial_congruency|name) + (1 + c_trial_congruency + c_trial_gender|workerid) + (1 + c_trial_congruency + c_trial_gender|lexeme), data=final_spr)
```

```{r}
summary(model_ten)
```


```{r}
final_spr %>%
  ggplot(aes(x= gender_link, y=resid_rt)) + 
  geom_point() + 
  geom_smooth(method="lm")
```


### Model Eleven

```{r}
link_residuals <- data.frame(
  frequency["workerid"],
  ResidLink = lm(gender_link~subject_information.party_alignment, data=subject_means_w_party)$resid
)
```

```{r}
final_spr <- left_join(final_spr,link_residuals,by="workerid")
```

```{r}
final_spr <- final_spr %>%
  
```


```{r}
model_eleven <- lmer(resid_rt~ResidIdeo * c_trial_gender + resid_lexeme_norm + log_all*poli_party(3_level) + (1 + ResidIdeo + resid_lexeme_norm + log_all*poli_party | name) + (1 + c_trial_gender + resid_lexeme_norm + log_all |workerid) + (1 + c_trial_gender + ResidIdeo + poli_party | lexeme))
```





## Other Shit




```{r}
final_spr <- final_spr %>%
  mutate(norm_skew = ifelse(lexeme_norm > 4, "female","male"))
```

```{r}
final_spr %>%
  ggplot(aes(x=gender_link,y=gender_trans)) +
  geom_point() +
  geom_smooth(method="lm")
```

```{r}
final_spr %>%
  ggplot(aes(x=gender_link,y=gender_total)) +
  geom_point() +
  geom_smooth(method="lm")
```

```{r}
final_spr %>%
  ggplot(aes(x=gender_trans,y=gender_total)) +
  geom_point() +
  geom_smooth(method="lm")
```

### Graphs

```{r}
ggplot(final_spr, aes(x=gender_total, y=resid_rt, color=norm_skew)) + 
  geom_point() + 
  geom_smooth(method="lm")
```


# Break Point: 10:09am 1 Dec


```{r}
final_spr %>%
  group_by(subject_information.party_alignment) %>%
  summarize(gender_trans = mean(gender_trans)) %>%
  ggplot(aes(x=subject_information.party_alignment,y=gender_trans)) + 
  geom_bar(stat="identity") + 
  geom_jitter(data=subject_means, aes(y=gender_trans,x=subject_information.party_alignment),height=0)
```

```{r}
final_spr %>%
  group_by(subject_information.party_alignment) %>%
  summarize(mean_gender_link = mean(gender_link)) %>%
  ggplot(aes(x=subject_information.party_alignment,y=mean_gender_link)) + 
  geom_bar(stat="identity")
```

**Calculating Speaker Means by Condition** 

```{r}
sprt_speaker_means <- sprt_data %>%
  group_by(condition,poli_party,workerid) %>%
  summarize(MeanRT=mean(resid_rt))
```

**Condition Means with Participant Means**

```{r}
sprt_data %>%
  group_by(condition,trial_gender) %>%
  summarize(MeanRT = mean(resid_rt), CI.Low = ci.low(resid_rt), CI.High = ci.high(resid_rt)) %>%
  mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High) %>%
  ggplot(aes(x=condition,y=MeanRT,color=trial_gender)) + 
  geom_point(size=3) + 
  geom_jitter(data = sprt_speaker_means, aes(y=MeanRT),alpha=.1,color='black') + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=.25) + 
  scale_color_manual(values = bran_palette, ) + 
  labs(x="Condition",y="Residual Reading Time", color="Trial Gender")
```

```{r}
ggsave("sprt_all.png", width=7,height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
```

```{r}
sprt_data %>%
  group_by(condition,trial_gender,poli_party) %>%
  summarize(MeanRT = mean(resid_rt), CI.Low = ci.low(resid_rt), CI.High = ci.high(resid_rt)) %>%
  mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High) %>%
  ggplot(aes(x=condition,y=MeanRT,color=trial_gender)) + 
  geom_point(size=3) + 
  geom_jitter(data = sprt_speaker_means, aes(y=MeanRT),alpha=.1,color='black') + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=.25) + 
  scale_color_manual(values = bran_palette, ) + 
  labs(x="Condition",y="Residual Reading Time", color="Trial Gender") +
  facet_wrap(~poli_party)
```

**Reading Time by Gender Ideology**

**Calculating Speaker Means by Ideology**

```{r}
sprt_speaker_means_ideology <- sprt_data %>%
  group_by(gender_total,workerid,trial_gender,trial_congruency,poli_party) %>%
  summarise(meanrt = mean(resid_rt))
```


```{r}
sprt_speaker_means_ideology %>%
  filter(!is.na(poli_party)) %>%
  ggplot(aes(x=gender_total,y=meanrt,color=trial_gender,linetype=trial_congruency)) + 
  geom_point() + 
  geom_smooth(method='lm') + 
  scale_color_manual(values = bran_palette, ) + 
  facet_wrap(~poli_party)
```

**Reading Time on Neologisms** 

```{r}
sprt_data %>%
  filter(!is.na(poli_party)) %>%
  group_by(gender_total,workerid,trial_gender,poli_party,condition) %>%
  summarise(meanrt = mean(resid_rt)) %>%
  ggplot(aes(x=gender_total,y=meanrt,color=trial_gender)) + 
  geom_point() + 
  geom_smooth(method='lm') + 
  scale_color_manual(values = bran_palette, ) + 
  facet_grid(condition~poli_party) 
```

```{r}
final_spr %>% 
  ggplot(aes(x))
```


```{r}
sprt_data %>%
  filter(!is.na(poli_party)) %>%
  filter(trial_congruency == "neutral") %>%
  group_by(gender_trans,workerid,trial_gender,poli_party) %>%
  summarise(meanrt = mean(resid_rt)) %>%
  ggplot(aes(x=gender_trans,y=meanrt,color=trial_gender)) + 
  geom_point() + 
  geom_smooth(method='lm') + 
  scale_color_manual(values = bran_palette, ) + 
  facet_wrap(~poli_party) 
```

```{r}
sprt_data %>%
  filter(!is.na(poli_party)) %>%
  filter(trial_congruency == "neutral") %>%
  group_by(gender_link,workerid,trial_gender,poli_party) %>%
  summarise(meanrt = mean(resid_rt)) %>%
  ggplot(aes(x=gender_link,y=meanrt,color=trial_gender)) + 
  geom_point() + 
  geom_smooth(method='lm') + 
  scale_color_manual(values = bran_palette, ) + 
  facet_wrap(~poli_party) 
```


```{r}
sprt_data <- merge(sprt_data,lex_freqs,by="lexeme") %>%
  mutate(mean_neutral = (sum(mean_left_neutral,mean_right_neutral))/2)
```


```{r}
sprt_data %>%
  filter(!is.na(poli_party)) %>%
  filter(trial_congruency == "neutral") %>%
  ggplot(aes(x=gender_total,y=resid_rt,color=trial_gender)) + 
  geom_point() + 
  geom_smooth(method='lm') + 
  scale_color_manual(values = bran_palette, ) + 
  labs(x="Gender Total",y="Residual Reading Time", color="Trial Gender")
```

```{r}
ggsave("sprt_neutral_gt.png", width=7,height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
```

**Reading Time by Item**

```{r}
sprt_data %>%
  group_by(condition,trial_gender,trial_congruency,lexeme) %>%
  summarize(MeanRT = mean(resid_rt), CI.Low = ci.low(resid_rt), CI.High = ci.high(resid_rt)) %>%
  mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High) %>%
  ggplot(aes(x=condition,y=MeanRT,color=trial_gender,shape=trial_congruency)) + 
  geom_point(size=3) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=.25) + 
  facet_wrap(~ lexeme) +
  theme(axis.text.x = element_text(angle = 45, vjust = .7, hjust=.7)) + 
  scale_color_manual(values = bran_palette)
```
**Whole-Party Means**

```{r}
sprt_data %>%
  filter(!is.na(poli_party)) %>%
  group_by(poli_party,condition,trial_gender,trial_congruency) %>%
  summarize(MeanRT = mean(resid_rt), CI.Low = ci.low(resid_rt), CI.High = ci.high(resid_rt)) %>%
  mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High) %>%
  ggplot(aes(x=condition,y=MeanRT,color=trial_gender,shape=trial_congruency)) + 
  geom_point(size=3) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=.25) + 
  facet_wrap(~ poli_party, nrow = 1) +
  theme(axis.text.x = element_text(angle = 45, vjust = .7, hjust=.7)) + 
  scale_color_manual(values = bran_palette) +
  labs(x="Condition", y="Residual Reading Time", shape="Trial Congruency", color="Trial Gender")
```

```{r}
ggsave("sprt_party.png", width=7,height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
```

**Modelling**

```{r}
sprt_model <- final_spr %>%
  mutate(c_gender_total = scale(gender_total)) %>%
  mutate(cage = scale(subject_information.age)) %>%
  mutate(mean_all = (mean_freq_left + mean_freq_right)/2) %>%
  mutate(c_mean_all = scale(mean_all)) %>%
  mutate(c_trial_congruency = as.numeric(as.factor(trial_congruency))-mean(as.numeric(as.factor(trial_congruency)))) %>%
  mutate(c_trial_gender = as.numeric(as.factor(trial_gender))-mean(as.numeric(as.factor(trial_gender)))) %>%
  mutate(c_indi_mean = scale(indi_mean))
```

```{r}
complex_model <- lmer(resid_rt~c_trial_congruency + c_gender_total + poli_party + c_mean_all + c_indi_mean + (1|workerid) + (1|lexeme) + (1|name),data = sprt_model)
```

```{r}
summary(complex_model)
```

### Auxiliary Analysis: Republicans

```{r}
final_spr %>%
  filter(poli_party == "Republican") %>%
  group_by(proliferate.condition,condition,trial_gender,trial_congruency) %>%
  summarize(MeanRT = mean(resid_rt), CI.Low = ci.low(resid_rt), CI.High = ci.high(resid_rt)) %>%
  mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High) %>%
  ggplot(aes(x=condition,y=MeanRT,color=trial_gender,shape=trial_congruency)) + 
  geom_point(size=3) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=.25) + 
  facet_wrap(~ proliferate.condition, nrow = 1) +
  theme(axis.text.x = element_text(angle = 45, vjust = .7, hjust=.7)) + 
  scale_color_manual(values = bran_palette) +
  labs(x="Condition", y="Residual Reading Time", shape="Trial Congruency", color="Trial Gender")
```

```{r}
spr_republicans <- sprt_model %>%
  filter(poli_party == "Republican")
```

```{r}
repub_model <- lmer(resid_rt ~ proliferate.condition + (1|workerid) + (1|name) + (1|lexeme),data=spr_republicans)
```

```{r}
summary(repub_model)
```

## Production Task Study

### Methods

### Analysis

**Data Read-in**

```{r}
prod_data <- read.csv("production_data.csv")
```

**Exclusions**

```{r}
prod_exclusion <- prod_data %>% filter(name=='attention') %>%
  group_by(workerid) %>%
  summarise(accuracy = mean(correct)) %>%
  mutate(exclude = ifelse(accuracy < 0.80,'Yes','No')) %>%
  filter(exclude == "Yes")
```

```{r}
prod_data <- prod_data[!(prod_data$workerid %in% prod_exclusion$workerid),]
```

**Additional Information** 

```{r}
prod_data <- prod_data %>%
  mutate(gender_trans = 100 - (rowMeans(prod_data[gender_transcendence_cols]))) %>%
  mutate(gender_link = rowMeans(prod_data[gender_linked_cols])) 

gender_all = c('gender_trans','gender_link')

prod_data <- prod_data %>%
  mutate(gender_total = rowMeans(prod_data[gender_all]))
``` 

```{r}
prod_data <- prod_data %>%
  filter(type == "critical") %>%
  mutate(response_gender = ifelse(response == "actress" | response == "anchorwoman" | response == "stewardess" | response == "businesswoman" | response == 'camerawoman' | response == 'congresswoman' | response == 'craftswoman' | response == 'crewwoman' | response == 'firewoman' | response == 'forewoman'  | response == 'heiress' | response == 'heroine' | response == 'hostess' | response == 'huntress' | response == 'laywoman' | response == 'policewoman' | response == 'saleswoman' | response == 'stuntwoman' | response == 'villainess' | response == 'weatherwoman',"female",ifelse(response == "anchor" | response == "flight attendant" | response == "businessperson" | response == 'camera operator' | response == 'congressperson' | response == 'craftsperson' | response == 'crewmember' | response == 'firefighter' | response == 'foreperson' | response == 'layperson' | response == 'police officer' | response == 'salesperson' | response == 'stunt double' | response == 'meteorologist',"neutral",ifelse(response == "anchorman" | response == "steward" | response == "businessman" | response == 'cameraman' | response == 'congressman' | response == 'craftsman' | response == 'crewman' | response == 'fireman' | response == 'foreman' | response == 'layman' | response == 'policeman' | response == 'salesman' | response == 'stuntman' | response == 'weatherman',"male",'male/neutral')))) %>%
  mutate(congruency = ifelse(gender == response_gender,"true","false")) %>%
  mutate(neutrality = ifelse(response_gender == "neutral","true","false"))%>%
  mutate(morph_type = ifelse(lexeme!= 'actor' & lexeme!= 'host' & lexeme !='hunter' & lexeme!= 'villain' & lexeme!= 'heir' & lexeme!= 'hero','compound','adoption')) %>%
  mutate(poli_party = ifelse(subject_information.party_alignment == 1 | subject_information.party_alignment == 2,'Republican',ifelse(subject_information.party_alignment == 4 | subject_information.party_alignment == 5,'Democrat','Non-Partisan'))) %>%
  mutate(response_neutral = ifelse(response_gender == "neutral" | response_gender == "male/neutral",1,0))
```

```{r}
prod_final <- left_join(prod_data,norming_means_neutral,by="lexeme")
prod_final <- left_join(prod_final,real_dists,by="lexeme")
```

## Preliminary Visualisations

### Neutral Production Rate by Norming

```{r}
prod_final %>% 
  group_by(lexeme,indi_mean) %>%
  summarize(mean_prop = mean(response_neutral)) %>%
  ggplot(aes(x=indi_mean,y=mean_prop,label=lexeme)) +
  geom_point() +
  geom_text() +
  geom_smooth(method="lm")
```


**Responses by Political Ideology**

```{r}
prod_data %>% 
  filter(!is.na(poli_party)) %>%
  filter(morph_type =="compound") %>%
  ggplot(aes(x=poli_party, fill=response_gender)) + 
  geom_bar(position="fill") + 
  facet_wrap(~gender) + 
  scale_fill_manual(values = bran_palette) + 
  labs(x="Participant Political Party", fill="Gender of Response", y="Proportion of Responses", title="Gender of Response by Gender of Stimulus Name") + 
  theme(text=element_text(size=15)) + 
  theme(axis.text.x = element_text(angle=25))
```

```{r}
ggsave("prod_all_poli.png", width=7,height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
``` 




```{r}
prod_data %>% 
  filter(!is.na(subject_information.party_alignment)) %>%
  filter(morph_type =="compound") %>%
  ggplot(aes(x=subject_information.party_alignment, fill=response_gender)) + 
  geom_bar(position="fill") + 
  facet_wrap(~gender) + 
  scale_fill_manual(values = bran_palette) + 
  labs(x="Participant Political Party", fill="Gender of Response", y="Proportion of Responses", title="Gender of Response by Gender of Stimulus Name")
```

**Gender of Response by Political Alignment and Gender Ideology**

```{r}
prod_data %>%
  filter(!is.na(poli_party)) %>%
  mutate(response_neutral = ifelse(response_gender == "neutral",1,0)) %>%
  filter(gender!="filler" & gender!= "attention" & gender!="" & morph_type=="compound") %>%
  group_by(gender,gender_total,poli_party) %>%
  summarise(proportion = mean(response_neutral)) %>%
  ggplot(aes(x=gender_total, y=proportion, color=gender)) +
    geom_point() + 
    geom_smooth() + 
    scale_color_manual(values = bran_palette) +
    facet_wrap(~poli_party) + 
    labs(x="Gender Ideology Score", y="Proportion of Gender Neutral Responses",color="Gender of Name Seen") + 
    theme(text=element_text(size=15))
```

```{r}
ggsave("prod_neutral_poli.png", width=10,height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
``` 

```{r}
prod_data %>%
  filter(!is.na(poli_party)) %>%
  mutate(response_neutral = ifelse(response_gender == "neutral",1,0)) %>%
  filter(gender!="filler" & gender!= "attention" & gender!="") %>%
  group_by(gender,subject_information.age,poli_party) %>%
  summarise(proportion = mean(response_neutral)) %>%
  ggplot(aes(x=subject_information.age, y=proportion, color=gender)) +
    geom_point() + 
    geom_smooth() + 
    scale_color_manual(values = bran_palette) 
```

```{r}
prod_data %>%
  filter(!is.na(poli_party)) %>%
  mutate(response_neutral = ifelse(response_gender == "neutral",1,0)) %>%
  filter(gender!="filler" & gender!= "attention" & gender!="") %>%
  group_by(gender,workerid,poli_party) %>%
  summarise(proportion = mean(response_neutral)) %>%
  ggplot(aes(x=poli_party, y=proportion, fill=poli_party)) +
    geom_boxplot(varwidth = T) + 
    scale_fill_manual(values=bran_palette) + 
    facet_wrap(~gender) + 
  theme(legend.position = "none") + 
  labs(x="Participant Political Party", y="Proportion",title="Mean Prop. of Neutral Responses by Stimuli Gender") + 
  theme(text=element_text(size=16)) + 
  theme(axis.text.x = element_text(angle=20))
```

```{r}
ggsave("prod_neutral_poli_box.png", width=7, height=5,path='/Users/branpap/Desktop/gender_processing/talks_and_papers/qp_paper/figures')
``` 

**Gender by Gender, no Ideology**

```{r}
prod_data %>%
  filter(morph_type =="compound") %>%
  ggplot(aes(x=gender, fill=response_gender)) + 
  geom_bar(position="fill") + 
  scale_fill_manual(values = bran_palette) + 
  labs(x="Stimulus Gender", fill="Gender of Response", y="Proportion of Responses", title="Gender of Response by Gender of Stimulus Name") +
  theme_minimal() + 
  geom_errorbar(aes(ymin=))
```

**Models**

```{r}
prod_data_compounds <- prod_data %>%
  filter(morph_type == "compound") %>%
  mutate(cgender_total = scale(gender_total)) %>%
  mutate(response_congruency = as.numeric(ifelse(congruency=="true","1","0"))) %>%
  mutate(cage = scale(subject_information.age)) %>%
  mutate(neutrality_binary = ifelse(neutrality=="true",1,0))
```

```{r}
final_dat <- merge(prod_data_compounds,lex_freqs,by="lexeme") %>%
  mutate(neutrality_binary = ifelse(neutrality=="true",1,0)) %>%
  filter(morph_type == "compound") %>%
  mutate(cgender_total = scale(gender_total)) %>%
  mutate(response_congruency = as.numeric(ifelse(congruency=="true","1","0"))) %>%
  mutate(cage = scale(subject_information.age)) %>%
  mutate(cmean_left_neutral = scale(mean_left_neutral)) %>%
  mutate(mean_all = (mean_left_neutral + mean_right_neutral)/2) %>%
  mutate(cmean_all = scale(mean_all))
```

```{r}
production_model_one <- lmer(neutrality_binary~cgender_total + poli_party + gender + cmean_all + (1|workerid) + (1|lexeme) + (1|name),data=final_dat)
```

```{r}
summary(production_model_one)
```


# Some Prop Tables

```{r}
(table(prod_data$subject_information.gender))
```



```{r}
prod_gender_table <- prod_data %>%
  group_by(workerid,subject_information.gender,poli_party) %>%
  summarise(subject_gender = paste(unique(subject_information.gender)))

table(prod_gender_table$subject_gender,prod_gender_table$poli_party)
```

```{r}
prod_data_all <- read.csv("production_data.csv") %>%
  filter(type=="filler_semantic" | type=="filler_grammatical") %>%
  group_by(lexeme,type) %>%
  summarise(lexeme=paste(unique(lexeme)))
```

```{r}
table(prod_data_all$type)
```

```{r}
participant_ages <- final_spr %>%
  select(workerid,poli_party,subject_information.age) %>%
  unique()
```

```{r}
participant_ages %>%
  filter(!is.na(poli_party)) %>%
  ggplot(aes(x=subject_information.age, fill=poli_party)) + 
  geom_density(alpha=.3, position="identity")
```

```{r}
participant_ages %>%
  group_by(poli_party) %>%
  summarise(mean=mean(subject_information.age, na.rm = TRUE))
```

```{r}
final_spr <- final_spr 
```

```{r}
final_spr %>%
  filter(!is.na(poli_party)) %>%
  filter(!is.na(young_old)) %>%
  filter(poli_party != "Non-Partisan") %>%
  group_by(form,poli_party,young_old) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_all > -5) %>%
  ggplot(aes(x=log_all,y=resid_rt_mean)) +
  geom_point() + 
  geom_smooth(method="lm") +
  facet_grid(young_old~poli_party) + 
  labs(x="Log Frequency",y="Mean Reading Time (Residual)") + 
  theme(text=element_text(size=14))
```

```{r}
ggsave("proc-freq-party.png", width=7,height=5,path='/Users/branpap/Desktop/gender_ideology/talks_and_papers/qp_paper/figures')
```

```{r}
final_spr %>%
  filter(!is.na(poli_party)) %>%
  filter(!is.na(young_old)) %>%
  filter(media_source > -5) %>%
  group_by(form,poli_party,young_old) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  filter(log_all > -5) %>%
  ggplot(aes(x=media_source,y=resid_rt_mean,label=form)) +
  geom_point() + 
  geom_smooth(method="lm") + 
  geom_text(size=4,nudge_y =.03) + 
  facet_grid(young_old~poli_party)
```

```{r}
final_spr %>%
  select(poli_party,log_left,log_right,log_all,media_source)
```

```{r}
temp <- final_spr %>%
  filter(!is.na(poli_party)) %>%
  filter(!is.na(young_old)) %>%
  filter(media_source > -5) %>%
  group_by(form,poli_party,young_old) %>%
  mutate(resid_rt_mean = mean(resid_rt)) %>%
  ungroup() %>%
  filter(log_all > -5)
```

```{r}
cors_window = temp %>% 
  group_by(poli_party,young_old) %>% 
  summarize(Correlation=round(cor.test(media_source,resid_rt_mean)$estimate,2),P=round(cor.test(media_source,resid_rt_mean)$p.value,5))
cors_window
```

```{r}
cors_log_all = temp %>% 
  group_by(poli_party,young_old) %>% 
  summarize(Correlation=round(cor.test(log_all,resid_rt_mean)$estimate,2),P=round(cor.test(log_all,resid_rt_mean)$p.value,5))
cors_log_all
```

```{r}
temp %>%
  cor(media_source, resid_rt_mean)
```

```{r}
cor(temp$media_source,temp$resid_rt_mean)
```

```{r}
final_spr %>%
  select(workerid,poli_party,subject_information.age) %>%
  unique() %>%
  summarise_all(funs(sum(is.na(.))))
```
```{r}
final_spr %>%
  select(workerid,poli_party,subject_information.age) %>%
  unique() %>%
  count(poli_party) 
```

```{r}
final_spr %>%
  select(workerid,poli_party,subject_information.age) %>%
  unique() %>%
  count(subject_information.age) 
```


```{r}
table(dem_temp$poli_party,dem_temp$subject_information.age, na.rm=TRUE)
```

```{r}
table(final_spr$young_old,final_spr$poli_party)
```


```{r}
final_spr %>%
  filter(!is.na(poli_party)) %>%
  filter(!is.na(subject_information.age)) %>%
  filter(trial_congruency == "neutral") %>%
  filter(lexeme != "flight attendant") %>%
  group_by(lexeme,trial_gender,poli_party,young_old) %>%
  mutate(lex_mean = mean(resid_rt)) %>%
  ggplot(aes(x=lexeme_norm,y=lex_mean, color=trial_gender,label=lexeme)) + 
  geom_point() + 
  geom_text() + 
  geom_smooth(method="lm") + 
  facet_grid(young_old~poli_party)
```

```{r}
final_spr %>%
  filter(trial_congruency == "neutral") %>%
  filter(lexeme != "flight attendant") %>%
  ggplot(aes(x=lexeme_norm, y=log_all)) + 
  geom_point() + 
  geom_smooth(method="lm")
```
```{r}
final_spr %>%
  filter(!is.na(poli_party)) %>%
  filter(trial_congruency == "neutral") %>%
  filter(lexeme != "flight attendant") %>%
  mutate(freq_high_low = cut_interval(log_all,n=2,labels=c("low","high"))) %>%
  ggplot(aes(x=lexeme_norm, y=log_all)) + 
  geom_point() + 
  geom_smooth(method="lm") + 
  facet_grid(freq_high_low~poli_party)
```
```{r}
final_spr %>%
  filter(!is.na(poli_party)) %>%
  filter(trial_congruency == "neutral") %>%
  filter(lexeme != "flight attendant") %>%
  mutate(freq_high_low = cut_interval(log_all,n=2,labels=c("low","high"))) %>%
  group_by(lexeme,trial_gender,poli_party,freq_high_low,lexeme_norm) %>%
  summarise(lex_mean = mean(resid_rt)) %>%
  ggplot(aes(x=lexeme_norm, y=lex_mean,color=trial_gender)) + 
  geom_point() + 
  geom_smooth(method="lm") + 
  facet_grid(freq_high_low~poli_party)
```







```{r}
temp_two <- final_spr %>%
  filter(!is.na(poli_party)) %>%
  filter(!is.na(subject_information.age)) %>%
  # filter(trial_congruency == "neutral") %>% 
  filter(lexeme != "flight attendant") %>% 
  group_by(trial_congruency) %>% 
  summarize(Correlation=round(cor.test(log_all,lexeme_norm)$estimate,2),P=round(cor.test(log_all,lexeme_norm)$p.value,5))
temp_two
```

```{r}
cors_poli_norm = temp_two %>% 
  group_by(poli_party,lexeme_norm) %>% 
  summarize(Correlation=round(cor.test(lexeme_norm,resid_rt_mean)$estimate,2),P=round(cor.test(lexeme_norm,resid_rt_mean)$p.value,5))
cors_log_all
```




```{r}
final_spr %>%
  group_by(trial_gender,trial_congruency,morph_type) %>%
  summarize(MeanRT = mean(resid_rt), CI.Low = ci.low(resid_rt), CI.High = ci.high(resid_rt)) %>%
  mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High) %>%
  ggplot(aes(x=morph_type,y=MeanRT,color=trial_gender)) + 
  geom_point() + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax), width=.25) + 
  facet_wrap(~trial_congruency)
```

